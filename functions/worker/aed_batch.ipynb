{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aed_lib import *\n",
    "import shutil\n",
    "import h5py\n",
    "from db import connect\n",
    "import sqlalchemy as sqal\n",
    "import datetime as dt\n",
    "import time # testing\n",
    "\n",
    "%env AWS_SECRET=DEV \n",
    "%env RECBUCKET=arbimon2\n",
    "%env WRITEBUCKET=ml-specs\n",
    "\n",
    "session, engine, metadata = connect() # RDS connection\n",
    "\n",
    "recordings = sqal.Table('recordings', metadata, autoload=True, autoload_with=engine)\n",
    "aeds = sqal.Table('audio_event_detections_clustering', metadata, autoload=True, autoload_with=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = \\\n",
    "{\n",
    "  \"recording_id\": [\n",
    "    1435107,\n",
    "    1435108,\n",
    "    1435109\n",
    "  ],\n",
    "  \"job_id\": 12014,\n",
    "  \"project_id\": 1060,\n",
    "  \"worker_id\": 2,\n",
    "  \"Amplitude Threshold\": 1.5,\n",
    "  \"Size Threshold\": [\n",
    "    1000,\n",
    "    1\n",
    "  ],\n",
    "  \"Filter Size\": [\n",
    "    5,\n",
    "    30\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handler(event):\n",
    "\n",
    "    #--- user inputs\n",
    "        # recording_id\n",
    "        # project_id\n",
    "        # job_id\n",
    "        # worker_id\n",
    "        # amplitude threshold\n",
    "        # filter size\n",
    "        # size threshold\n",
    "\n",
    "    rec_ids = [int(i) for i in np.sort(np.array(event['recording_id']))]\n",
    "    proj_id = event['project_id']\n",
    "    job_id = event['job_id']\n",
    "\n",
    "    # define variables\n",
    "    temp_dir = '/home/ubuntu/workspace-lambda/tmp'\n",
    "    rec_dir = temp_dir+'/recordings/'\n",
    "    image_dir = temp_dir+'/images'\n",
    "    det_dir = temp_dir+'/detection_data/'\n",
    "    feature_file_prefix = temp_dir+'/'+str(job_id)+'_'+str(event['worker_id'])\n",
    "\n",
    "    #--- create temp directories\n",
    "    if not os.path.exists(temp_dir): ########################################################### delete\n",
    "        os.mkdir(temp_dir)\n",
    "        os.mkdir(rec_dir)\n",
    "        os.mkdir(image_dir)\n",
    "        os.mkdir(det_dir)\n",
    "    else:\n",
    "        shutil.rmtree(temp_dir)\n",
    "        os.mkdir(temp_dir)\n",
    "        os.mkdir(rec_dir)\n",
    "        os.mkdir(image_dir)\n",
    "        os.mkdir(det_dir)\n",
    "\n",
    "    #--- find the recording URIs for downloading\n",
    "    query = sqal.select([recordings.c.uri,\n",
    "                         recordings.c.datetime]).where(recordings.columns.recording_id.in_(rec_ids)) \\\n",
    "                        .order_by(recordings.c.recording_id)\n",
    "    result = session.execute(query).fetchall()\n",
    "    rec_uris = [i[0] for i in result]\n",
    "    rec_dts = [i[1] for i in result]\n",
    "    rec_dts = [(i.hour+i.minute/60)/24 for i in rec_dts] # convert datetime to fraction of day\n",
    "    rec_dts = [to_unitcirc(i) for i in rec_dts]\n",
    "\n",
    "    #--- process recordings\n",
    "    for n, rec in enumerate(rec_uris[:1]):\n",
    "\n",
    "        print(rec)\n",
    "\n",
    "        image_uri = 'audio_events/'+os.environ['AWS_SECRET'].lower()+'/detection/'+str(job_id)+'/png/'+str(rec_ids[n])+'/'\n",
    "\n",
    "        if not os.path.exists(image_dir+'/'+str(rec_ids[n])):\n",
    "            os.mkdir(image_dir+'/'+str(rec_ids[n]))\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        #--- download recording and compute spectrogram\n",
    "        f, t, S = download_and_get_spec(rec, os.environ['RECBUCKET'], rec_dir);\n",
    "\n",
    "        #--- detect events\n",
    "        objs = find_events(S, f, t, event['Filter Size'][0], event['Filter Size'][1], 0.95, event['Amplitude Threshold'], event['Size Threshold'][0], event['Size Threshold'][1])\n",
    "        print(len(objs))\n",
    "\n",
    "        print(time.time() - t0)\n",
    "\n",
    "        #--- bulk insert audio events to db\n",
    "        result = session.execute(\n",
    "\n",
    "            aeds.insert(),\n",
    "\n",
    "            [{'job_id': int(job_id),\n",
    "              'recording_id': int(rec_ids[n]),\n",
    "              'time_min': float(t[ob[1].start]),\n",
    "              'time_max': float(t[ob[1].stop-1]),\n",
    "              'frequency_min': float(f[ob[0].start]),\n",
    "              'frequency_max': float(f[ob[0].stop-1]),\n",
    "              'aed_number': int(c),\n",
    "              'uri_image': image_uri+str(c)+'.png'\n",
    "             }\n",
    "\n",
    "             for c, ob in enumerate(objs)]\n",
    "\n",
    "        )\n",
    "        session.commit()\n",
    "\n",
    "        #--- compute audio event features\n",
    "        compute_features(objs, rec_ids[n], rec_dts[n], S, f, t, feature_file_prefix)\n",
    "\n",
    "        #--- store roi images\n",
    "        store_roi_images(S, objs, rec_ids[n], image_dir, image_uri)\n",
    "\n",
    "    #--- query for aed_ids\n",
    "    print('mapping ids...')\n",
    "    query = sqal.select([aeds.c.aed_id, \\\n",
    "                         aeds.c.recording_id, \\\n",
    "                         aeds.c.aed_number]).where(sqal.and_(aeds.c.job_id==job_id, \\\n",
    "                                                             aeds.c.recording_id.in_(rec_ids)))\n",
    "    result = session.execute(query).fetchall()\n",
    "    key_dict = dict({i[1:]:i[0] for i in result}) # dictionary mapping recording and aed_number to aed_key\n",
    "\n",
    "    aed_ids = np.load(feature_file_prefix+'_ids.npy') # file contains ae recording ids and ae number\n",
    "    aed_ids = [key_dict[tuple(i)] for i in aed_ids]\n",
    "    np.save(feature_file_prefix+'_ids.npy', aed_ids) # file now contains list of aed_ids from database\n",
    "\n",
    "    session.close()\n",
    "\n",
    "    #--- upload to S3\n",
    "    s3.Bucket(os.environ['WRITEBUCKET']).upload_file(feature_file_prefix+'_features.npy', \n",
    "                                                     'audio_events/'+os.environ['AWS_SECRET'].lower()+'/detection/'+str(job_id)+(feature_file_prefix+'_features.npy').split(temp_dir)[-1])\n",
    "    s3.Bucket(os.environ['WRITEBUCKET']).upload_file(feature_file_prefix+'_ids.npy', \n",
    "                                                     'audio_events/'+os.environ['AWS_SECRET'].lower()+'/detection/'+str(job_id)+(feature_file_prefix+'_ids.npy').split(temp_dir)[-1])\n",
    "\n",
    "    shutil.rmtree(temp_dir)\n",
    "\n",
    "    return {'status' : 200}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.colors as colors\n",
    "# import matplotlib.patches as patches\n",
    "\n",
    "# objs = find_events(S, f, t, event['Filter Size'][0], event['Filter Size'][1], 0.95, event['Amplitude Threshold'], event['Size Threshold'][0], event['Size Threshold'][1])\n",
    "\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.pcolormesh(t, f/1000, S, cmap='Greys')\n",
    "# for c, i in enumerate(objs):\n",
    "#     flo = min(f[i[0]])\n",
    "#     fhi = max(f[i[0]])\n",
    "#     tlo = min(t[i[1]])\n",
    "#     thi = max(t[i[1]])\n",
    "#     rect = patches.Rectangle((tlo,flo/1000),thi-tlo,fhi/1000-flo/1000,linewidth=1,edgecolor='r',facecolor='none')\n",
    "#     plt.gca().add_patch(rect)\n",
    "\n",
    "# plt.xticks(np.arange(min(t), max(t)+1, 1.0))\n",
    "# plt.show\n",
    "\n",
    "# if not os.path.exists(str(rec_ids[n])):\n",
    "#     os.mkdir(str(rec_ids[n]))\n",
    "# store_roi_images(S, objs, rec_ids[n], './', image_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p36)",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
